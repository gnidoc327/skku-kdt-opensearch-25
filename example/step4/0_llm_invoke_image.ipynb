{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Step 4-0. LLM 이미지 분석 (RAG 파이프라인)\n텍스트로 이미지를 검색한 후, Claude LLM에게 이미지를 분석하도록 요청합니다.\n\n## 배경 지식\n\n### RAG (Retrieval-Augmented Generation)\n- **RAG = 검색(Retrieval) + 생성(Generation)**\n- 기존 LLM은 학습된 데이터만 기반으로 답변을 생성하지만, RAG는 **외부 지식을 검색해서 참고**한 뒤 더 정확한 답변을 생성\n- 이 실습에서는: 사용자 질문 → OpenSearch 벡터 검색 → 검색된 이미지를 LLM에 전달 → 이미지 설명 생성\n\n### LLM에 외부 데이터를 주입하는 3가지 방법\n1. **Prompt Engineering**: 필요한 값을 프롬프트에 직접 입력\n2. **RAG**: DB에서 유사한 데이터만 추출해서 프롬프트에 넣기 (프롬프트 길이 제한 대응)\n3. **Fine Tuning**: 데이터가 너무 많은 경우 모델 자체를 학습 (비용이 비싸고 최소 10MB 이상 데이터 필요)"
  },
  {
   "cell_type": "code",
   "source": "!pip install -q boto3==1.38.46 opensearch-py==2.8.0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T09:12:18.772764Z",
     "start_time": "2026-02-12T09:12:17.957472Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 설정 (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T09:12:18.787077Z",
     "start_time": "2026-02-12T09:12:18.782563Z"
    }
   },
   "source": [
    "import os, json\n",
    "\n",
    "# Step 0에서 저장한 설정 불러오기\n",
    "try:\n",
    "    with open(\"../config.json\") as f:\n",
    "        _config = json.load(f)\n",
    "    print(\"✅ config.json 로드 완료\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"❌ config.json을 찾을 수 없습니다. Step 0 노트북을 먼저 실행해주세요.\")\n",
    "\n",
    "HOST = _config.get(\"OPENSEARCH_HOST\")\n",
    "if not HOST:\n",
    "    raise ValueError(\"❌ config.json에 OPENSEARCH_HOST 값이 없습니다. Step 0 노트북을 먼저 실행해주세요.\")\n",
    "DEFAULT_REGION = _config.get(\"DEFAULT_REGION\", \"ap-northeast-2\")\n",
    "BEDROCK_REGION = _config.get(\"BEDROCK_REGION\", \"us-east-1\")\n",
    "PROFILE = _config.get(\"PROFILE\", \"skku-opensearch-session\")\n",
    "\n",
    "# 멀티모달 검색 설정 (Nova)\n",
    "MULTIMODAL_INDEX_NAME = 'nova-image-test'\n",
    "MULTIMODAL_EMBEDDING_MODEL_ID = 'amazon.nova-2-multimodal-embeddings-v1:0'\n",
    "VECTOR_DIMENSION = 1024\n",
    "\n",
    "# LLM 설정\n",
    "# LLM_MODEL_ID = \"us.anthropic.claude-opus-4-6-v1\"\n",
    "LLM_MODEL_ID = \"us.anthropic.claude-sonnet-4-5-20250929-v1:0\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ config.json 로드 완료\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OpenSearch 클라이언트 생성"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T09:12:18.811712Z",
     "start_time": "2026-02-12T09:12:18.800685Z"
    }
   },
   "source": [
    "import boto3\n",
    "from opensearchpy import OpenSearch, AWSV4SignerAuth, RequestsHttpConnection\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session(profile_name=PROFILE).get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, DEFAULT_REGION, service)\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': HOST, 'port': 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "print(\"OpenSearch 클라이언트 생성 완료\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch 클라이언트 생성 완료\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bedrock 클라이언트 생성 및 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T09:12:18.887210Z",
     "start_time": "2026-02-12T09:12:18.820650Z"
    }
   },
   "source": "import json\nimport base64\nimport math\nfrom opensearchpy.exceptions import RequestError\n\nsession = boto3.Session(profile_name=PROFILE)\nbedrock_client = session.client(\n    \"bedrock-runtime\",\n    region_name=BEDROCK_REGION,\n)\nprint(\"Bedrock client created successfully.\")\n\ndef normalize_vector(vec):\n    \"\"\"벡터를 L2 정규화합니다.\"\"\"\n    norm = math.sqrt(sum(x * x for x in vec))\n    return [x / norm for x in vec] if norm > 0 else vec\n\ndef get_text_embedding(text, model_id):\n    \"\"\"Nova 멀티모달 모델을 사용하여 텍스트를 벡터로 변환합니다.\"\"\"\n    body = json.dumps({\n        \"taskType\": \"SINGLE_EMBEDDING\",\n        \"singleEmbeddingParams\": {\n            \"embeddingPurpose\": \"GENERIC_RETRIEVAL\",\n            \"embeddingDimension\": VECTOR_DIMENSION,\n            \"text\": {\n                \"truncationMode\": \"END\",\n                \"value\": text\n            }\n        }\n    })\n    response = bedrock_client.invoke_model(\n        body=body, modelId=model_id, accept=\"application/json\", contentType=\"application/json\"\n    )\n    response_body = json.loads(response.get(\"body\").read())\n    return normalize_vector(response_body[\"embeddings\"][0][\"embedding\"])\n\ndef search_similar_image(index_name, query_vector):\n    \"\"\"OpenSearch에서 벡터 검색을 수행하여 가장 유사한 이미지 경로를 반환합니다.\"\"\"\n    search_query = {\n        \"size\": 1,\n        \"query\": {\"knn\": {\"content_vector\": {\"vector\": query_vector, \"k\": 1}}}\n    }\n    try:\n        response = client.search(index=index_name, body=search_query)\n        hits = response['hits']['hits']\n        if not hits:\n            return None\n        return hits[0]['_source'].get('image_path')\n    except RequestError as e:\n        print(f\"Error during OpenSearch search: {e.info}\")\n        return None\n\ndef image_to_base64(image_path):\n    \"\"\"이미지 파일을 Base64로 인코딩합니다.\"\"\"\n    if not os.path.exists(image_path):\n        print(f\"Error: Image file not found at {image_path}\")\n        return None\n    try:\n        with open(image_path, \"rb\") as image_file:\n            return base64.b64encode(image_file.read()).decode('utf-8')\n    except Exception as e:\n        print(f\"Error encoding image {image_path}: {e}\")\n        return None\n\ndef get_image_description_from_llm(base64_image, user_question):\n    \"\"\"Claude Sonnet 모델에게 이미지를 보여주고 설명을 요청합니다.\"\"\"\n    body = json.dumps({\n        \"anthropic_version\": \"bedrock-2023-05-31\",\n        \"max_tokens\": 300,\n        \"temperature\": 0.7,\n        \"top_p\": 0.9,\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image\",\n                        \"source\": {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": base64_image},\n                    },\n                    {\n                        \"type\": \"text\",\n                        \"text\": f\"이 이미지는 '{user_question}'이라는 질문으로 검색된 결과입니다. 이미지에 대해 친절하고 상세하게 설명해주세요.\"\n                    }\n                ],\n            }\n        ]\n    })\n\n    response = bedrock_client.invoke_model(\n        body=body, modelId=LLM_MODEL_ID, accept=\"application/json\", contentType=\"application/json\"\n    )\n    response_body = json.loads(response.get(\"body\").read())\n    return response_body['content'][0]['text']",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedrock client created successfully.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "# 인덱스에 데이터가 업로드되었는지 확인\nif not client.indices.exists(index=MULTIMODAL_INDEX_NAME):\n    print(f\"❌ '{MULTIMODAL_INDEX_NAME}' 인덱스가 존재하지 않습니다.\")\n    print(\"   → Step 3-2b (Nova 이미지 임베딩 데이터 업로드) 노트북을 먼저 실행해주세요.\")\nelse:\n    _doc_count = client.count(index=MULTIMODAL_INDEX_NAME)['count']\n    if _doc_count == 0:\n        print(f\"⏳ '{MULTIMODAL_INDEX_NAME}' 인덱스는 있지만 검색 가능한 문서가 0개입니다.\")\n        print(\"   → 데이터 업로드 직후라면 인덱싱 중일 수 있습니다. 잠시 후 다시 실행해주세요.\")\n    else:\n        print(f\"✅ '{MULTIMODAL_INDEX_NAME}' 인덱스에 {_doc_count}개의 문서가 준비되어 있습니다.\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T09:12:19.349694Z",
     "start_time": "2026-02-12T09:12:18.894384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 'nova-image-test' 인덱스는 있지만 검색 가능한 문서가 0개입니다.\n",
      "   → 데이터 업로드 직후라면 인덱싱 중일 수 있습니다. 잠시 후 다시 실행해주세요.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 실행: 이미지 검색 + LLM 분석"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T09:12:20.398130Z",
     "start_time": "2026-02-12T09:12:19.364370Z"
    }
   },
   "source": [
    "# Nova 모델은 한국어를 지원하므로 한국어로 검색합니다\n",
    "# TODO: 검색할 질문을 바꿔보세요!\n",
    "user_query = \"꽃 위에 벌\"\n",
    "\n",
    "# 1. 텍스트-이미지 검색\n",
    "print(f\"\\n1. '{user_query}'와(과) 유사한 이미지를 검색합니다...\")\n",
    "query_vector = get_text_embedding(user_query, MULTIMODAL_EMBEDDING_MODEL_ID)\n",
    "\n",
    "found_image_path = search_similar_image(MULTIMODAL_INDEX_NAME, query_vector)\n",
    "if not found_image_path:\n",
    "    print(\"관련 이미지를 찾지 못했습니다.\")\n",
    "else:\n",
    "    print(f\"   - 이미지 찾음: {found_image_path}\")\n",
    "\n",
    "    # 2. 이미지 분석 및 설명 생성\n",
    "    print(\"\\n2. 찾은 이미지를 분석하여 설명을 생성합니다...\")\n",
    "    base64_image_data = image_to_base64(found_image_path)\n",
    "\n",
    "    description = get_image_description_from_llm(base64_image_data, user_query)\n",
    "\n",
    "    # 3. 최종 결과 출력\n",
    "    print(\"\\n--- 최종 결과 ---\")\n",
    "    print(f\"검색된 이미지: {found_image_path}\")\n",
    "    print(f\"\\n이미지 설명:\")\n",
    "    print(description)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. '꽃 위에 벌'와(과) 유사한 이미지를 검색합니다...\n",
      "관련 이미지를 찾지 못했습니다.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": "## 실습 과제\n\n### 과제: 다양한 LLM으로 테스트하고 결과와 응답 속도를 비교해보기\n위 설정 셀에서 `LLM_MODEL_ID`를 변경하여 다시 실행해보세요.\n\n| 모델 | Model ID | 특징 |\n|------|----------|------|\n| Claude Sonnet 4.5 | `us.anthropic.claude-sonnet-4-5-20250929-v1:0` | 균형 잡힌 성능 (기본) |\n| Claude Opus 4.6 | `us.anthropic.claude-opus-4-6-v1` | 최고 성능, 느림 |\n\n- `user_query`도 다양하게 바꿔보며 테스트해보세요",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}